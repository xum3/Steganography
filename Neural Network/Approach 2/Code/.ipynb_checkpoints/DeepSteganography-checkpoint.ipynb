{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports necessary libraries and modules\n",
    "from itertools import islice\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import utils\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os \n",
    "import pickle\n",
    "from torchvision import datasets, utils\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    "from random import shuffle\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory path\n",
    "os.chdir(\"..\")\n",
    "#cwd = 'input'\n",
    "\n",
    "# Hyper Parameters\n",
    "num_epochs = 3\n",
    "batch_size = 2\n",
    "learning_rate = 0.0001\n",
    "beta = 1\n",
    "\n",
    "# Mean and std deviation of imagenet dataset. Source: http://cs231n.stanford.edu/reports/2017/pdfs/101.pdf\n",
    "std = [0.229, 0.224, 0.225]\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "\n",
    "# TODO: Define train, validation and models\n",
    "MODELS_PATH = '/Users/chenwang/Desktop/DeepSteg-master/output/models' \n",
    "\n",
    "# TRAIN_PATH = cwd+'/train/'\n",
    "# VALID_PATH = cwd+'/valid/'\n",
    "VALID_PATH = '/Users/chenwang/Desktop/data3/val' \n",
    "TRAIN_PATH = '/Users/chenwang/Desktop/data3/train' \n",
    "TEST_PATH = '/Users/chenwang/Desktop/data3/test' \n",
    "\n",
    "if not os.path.exists(MODELS_PATH): os.mkdir(MODELS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set of useful functions we are going to need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customized_loss(S_prime, C_prime, S, C, B):\n",
    "    ''' Calculates loss specified on the paper.'''\n",
    "    \n",
    "    loss_cover = torch.nn.functional.mse_loss(C_prime, C)\n",
    "    loss_secret = torch.nn.functional.mse_loss(S_prime, S)\n",
    "    loss_all = loss_cover + B * loss_secret\n",
    "    return loss_all, loss_cover, loss_secret\n",
    "\n",
    "def denormalize(image, std, mean):\n",
    "    ''' Denormalizes a tensor of images.'''\n",
    "\n",
    "    for t in range(3):\n",
    "        image[t, :, :] = (image[t, :, :] * std[t]) + mean[t]\n",
    "    return image\n",
    "\n",
    "def imshow(img, idx, learning_rate, beta):\n",
    "    '''Prints out an image given in tensor format.'''\n",
    "    \n",
    "    img = denormalize(img, std, mean)\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.title('Example '+str(idx)+', lr='+str(learning_rate)+', B='+str(beta))\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def gaussian(tensor, mean=0, stddev=0.1):\n",
    "    '''Adds random noise to a tensor.'''\n",
    "    \n",
    "    noise = torch.nn.init.normal(torch.Tensor(tensor.size()), 0, 0.1)\n",
    "    return Variable(tensor + noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The author used 3x3, 4x4 and 5x5 each for the first four layers and the concatenated them and passed them to the final layer. \n",
    "\n",
    "This architecture was replicated exactly in each of the layers. Output of PrepNetwork (secret image preapred to merge with cover) is concatenated to the cover and fed into the hidding network. The hidding network hides the secret image in the PrepNetwork's output and returns the hidden image. This is fed into the Reveal network to output the message, that should be close to the secret image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation Network (2 conv layers)\n",
    "class PrepNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PrepNetwork, self).__init__()\n",
    "        self.initialP3 = nn.Sequential(\n",
    "            nn.Conv2d(3, 50, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=3, padding=1),\n",
    "            nn.ReLU())\n",
    "        self.initialP4 = nn.Sequential(\n",
    "            nn.Conv2d(3, 50, kernel_size=4, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=4, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=4, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=4, padding=2),\n",
    "            nn.ReLU())\n",
    "        self.initialP5 = nn.Sequential(\n",
    "            nn.Conv2d(3, 50, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=5, padding=2),\n",
    "            nn.ReLU())\n",
    "        self.finalP3 = nn.Sequential(\n",
    "            nn.Conv2d(150, 50, kernel_size=3, padding=1),\n",
    "            nn.ReLU())\n",
    "        self.finalP4 = nn.Sequential(\n",
    "            nn.Conv2d(150, 50, kernel_size=4, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=4, padding=2),\n",
    "            nn.ReLU())\n",
    "        self.finalP5 = nn.Sequential(\n",
    "            nn.Conv2d(150, 50, kernel_size=5, padding=2),\n",
    "            nn.ReLU())\n",
    "\n",
    "    def forward(self, p):\n",
    "        p1 = self.initialP3(p)\n",
    "        p2 = self.initialP4(p)\n",
    "        p3 = self.initialP5(p)\n",
    "        mid = torch.cat((p1, p2, p3), 1)\n",
    "        p4 = self.finalP3(mid)\n",
    "        p5 = self.finalP4(mid)\n",
    "        p6 = self.finalP5(mid)\n",
    "        out = torch.cat((p4, p5, p6), 1)\n",
    "        return out\n",
    "\n",
    "# Hiding Network (5 conv layers)\n",
    "class HidingNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HidingNetwork, self).__init__()\n",
    "        self.initialH3 = nn.Sequential(\n",
    "            nn.Conv2d(153, 50, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=3, padding=1),\n",
    "            nn.ReLU())\n",
    "        self.initialH4 = nn.Sequential(\n",
    "            nn.Conv2d(153, 50, kernel_size=4, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=4, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=4, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=4, padding=2),\n",
    "            nn.ReLU())\n",
    "        self.initialH5 = nn.Sequential(\n",
    "            nn.Conv2d(153, 50, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=5, padding=2),\n",
    "            nn.ReLU())\n",
    "        self.finalH3 = nn.Sequential(\n",
    "            nn.Conv2d(150, 50, kernel_size=3, padding=1),\n",
    "            nn.ReLU())\n",
    "        self.finalH4 = nn.Sequential(\n",
    "            nn.Conv2d(150, 50, kernel_size=4, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=4, padding=2),\n",
    "            nn.ReLU())\n",
    "        self.finalH5 = nn.Sequential(\n",
    "            nn.Conv2d(150, 50, kernel_size=5, padding=2),\n",
    "            nn.ReLU())\n",
    "        self.finalH = nn.Sequential(\n",
    "            nn.Conv2d(150, 3, kernel_size=1, padding=0))\n",
    "        \n",
    "    def forward(self, h):\n",
    "        h1 = self.initialH3(h)\n",
    "        h2 = self.initialH4(h)\n",
    "        h3 = self.initialH5(h)\n",
    "        mid = torch.cat((h1, h2, h3), 1)\n",
    "        h4 = self.finalH3(mid)\n",
    "        h5 = self.finalH4(mid)\n",
    "        h6 = self.finalH5(mid)\n",
    "        mid2 = torch.cat((h4, h5, h6), 1)\n",
    "        out = self.finalH(mid2)\n",
    "        out_noise = gaussian(out.data, 0, 0.1)\n",
    "        return out, out_noise\n",
    "\n",
    "# Reveal Network (2 conv layers)\n",
    "class RevealNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RevealNetwork, self).__init__()\n",
    "        self.initialR3 = nn.Sequential(\n",
    "            nn.Conv2d(3, 50, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=3, padding=1),\n",
    "            nn.ReLU())\n",
    "        self.initialR4 = nn.Sequential(\n",
    "            nn.Conv2d(3, 50, kernel_size=4, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=4, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=4, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=4, padding=2),\n",
    "            nn.ReLU())\n",
    "        self.initialR5 = nn.Sequential(\n",
    "            nn.Conv2d(3, 50, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=5, padding=2),\n",
    "            nn.ReLU())\n",
    "        self.finalR3 = nn.Sequential(\n",
    "            nn.Conv2d(150, 50, kernel_size=3, padding=1),\n",
    "            nn.ReLU())\n",
    "        self.finalR4 = nn.Sequential(\n",
    "            nn.Conv2d(150, 50, kernel_size=4, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(50, 50, kernel_size=4, padding=2),\n",
    "            nn.ReLU())\n",
    "        self.finalR5 = nn.Sequential(\n",
    "            nn.Conv2d(150, 50, kernel_size=5, padding=2),\n",
    "            nn.ReLU())\n",
    "        self.finalR = nn.Sequential(\n",
    "            nn.Conv2d(150, 3, kernel_size=1, padding=0))\n",
    "\n",
    "    def forward(self, r):\n",
    "        r1 = self.initialR3(r)\n",
    "        r2 = self.initialR4(r)\n",
    "        r3 = self.initialR5(r)\n",
    "        mid = torch.cat((r1, r2, r3), 1)\n",
    "        r4 = self.finalR3(mid)\n",
    "        r5 = self.finalR4(mid)\n",
    "        r6 = self.finalR5(mid)\n",
    "        mid2 = torch.cat((r4, r5, r6), 1)\n",
    "        out = self.finalR(mid2)\n",
    "        return out\n",
    "\n",
    "# Join three networks in one module\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.m1 = PrepNetwork()\n",
    "        self.m2 = HidingNetwork()\n",
    "        self.m3 = RevealNetwork()\n",
    "\n",
    "    def forward(self, secret, cover):\n",
    "        x_1 = self.m1(secret)\n",
    "        mid = torch.cat((x_1, cover), 1)\n",
    "        x_2, x_2_noise = self.m2(mid)\n",
    "        x_3 = self.m3(x_2_noise)\n",
    "        return x_2, x_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates net object\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create loaders for normalized training, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/torchvision/transforms/transforms.py:209: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  \"please use transforms.Resize instead.\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found 0 files in subfolders of: /Users/chenwang/Desktop/data3/train\nSupported extensions are: .jpg,.jpeg,.png,.ppm,.bmp,.pgm,.tif,.tiff,.webp",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-48e29b0897a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         transforms.Normalize(mean=mean,\n\u001b[0;32m---> 11\u001b[0;31m         std=std)\n\u001b[0m\u001b[1;32m     12\u001b[0m         ])), batch_size=batch_size, num_workers=1, \n\u001b[1;32m     13\u001b[0m         pin_memory=True, shuffle=True, drop_last=True)\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    207\u001b[0m                                           \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                                           \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m                                           is_valid_file=is_valid_file)\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             raise (RuntimeError(\"Found 0 files in subfolders of: \" + self.root + \"\\n\"\n\u001b[0;32m---> 97\u001b[0;31m                                 \"Supported extensions are: \" + \",\".join(extensions)))\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found 0 files in subfolders of: /Users/chenwang/Desktop/data3/train\nSupported extensions are: .jpg,.jpeg,.png,.ppm,.bmp,.pgm,.tif,.tiff,.webp"
     ]
    }
   ],
   "source": [
    "# Creates training set\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.ImageFolder(\n",
    "        TRAIN_PATH,\n",
    "        transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        #transforms.Scale(256),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean,\n",
    "        std=std)\n",
    "        ])), batch_size=batch_size, num_workers=1, \n",
    "        pin_memory=True, shuffle=True, drop_last=True)\n",
    "\n",
    "# Creates test set\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.ImageFolder(\n",
    "        TEST_PATH, \n",
    "        transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        #transforms.Scale(256),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean,\n",
    "        std=std)\n",
    "        ])), batch_size=2, num_workers=1, \n",
    "        pin_memory=True, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the model and validate it, saving the best model. We use Adam as an optimizer as the paper specifies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_loader, beta, learning_rate):\n",
    "    \n",
    "    # Save optimizer\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    \n",
    "    loss_history = []\n",
    "    # Iterate over batches performing forward and backward passes\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Train mode\n",
    "        net.train()\n",
    "        \n",
    "        train_losses = []\n",
    "        # Train one epoch\n",
    "        for idx, train_batch in enumerate(train_loader):\n",
    "\n",
    "            data, _  = train_batch\n",
    "\n",
    "            # Saves secret images and secret covers\n",
    "            train_covers = data[:len(data)//2]\n",
    "            train_secrets = data[len(data)//2:]\n",
    "            \n",
    "            # Creates variable from secret and cover images\n",
    "            train_secrets = Variable(train_secrets, requires_grad=False)\n",
    "            train_covers = Variable(train_covers, requires_grad=False)\n",
    "\n",
    "            # Forward + Backward + Optimize\n",
    "            optimizer.zero_grad()\n",
    "            train_hidden, train_output = net(train_secrets, train_covers)\n",
    "\n",
    "            # Calculate loss and perform backprop\n",
    "            train_loss, train_loss_cover, train_loss_secret = customized_loss(train_output, train_hidden, train_secrets, train_covers, beta)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Saves training loss\n",
    "            train_losses.append(train_loss.data)\n",
    "            loss_history.append(train_loss.data)\n",
    "            \n",
    "            # Prints mini-batch losses\n",
    "            print('Training: Batch {0}/{1}. Loss of {2:.4f}, cover loss of {3:.4f}, secret loss of {4:.4f}'.format(idx+1, len(train_loader), train_loss.data, train_loss_cover.data, train_loss_secret.data))\n",
    "    \n",
    "        torch.save(net.state_dict(), MODELS_PATH+'Epoch N{}.pkl'.format(epoch+1))\n",
    "        \n",
    "        mean_train_loss = np.mean(train_losses)\n",
    "    \n",
    "        # Prints epoch average loss\n",
    "        print ('Epoch [{0}/{1}], Average_loss: {2:.4f}'.format(\n",
    "                epoch+1, num_epochs, mean_train_loss))\n",
    "    \n",
    "    return net, mean_train_loss, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net, mean_train_loss, loss_history = train_model(train_loader, beta, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot loss through epochs\n",
    "# plt.plot(loss_history)\n",
    "# plt.title('Model loss')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('Batch')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test the model and print out a few images so we can visually see how good a job the model did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n"
     ]
    }
   ],
   "source": [
    "# net.load_state_dict(torch.load(MODELS_PATH+'Epoch N4.pkl'))\n",
    "\n",
    "# Switch to evaluate mode\n",
    "net.eval()\n",
    "\n",
    "test_losses = []\n",
    "# Show images\n",
    "for idx, test_batch in enumerate(test_loader):\n",
    "     # Saves images\n",
    "    data, _ = test_batch\n",
    "\n",
    "    # Saves secret images and secret covers\n",
    "    test_secret = data[:len(data)//2]\n",
    "    test_cover = data[len(data)//2:]\n",
    "\n",
    "    # Creates variable from secret and cover images\n",
    "    with torch.no_grad():\n",
    "        test_secret = Variable(test_secret)\n",
    "        test_cover = Variable(test_cover)\n",
    "#     test_secret = Variable(test_secret, volatile=True)\n",
    "#     test_cover = Variable(test_cover, volatile=True)\n",
    "\n",
    "    # Compute output\n",
    "    test_hidden, test_output = net(test_secret, test_cover)\n",
    "    \n",
    "    # Calculate loss\n",
    "    test_loss, loss_cover, loss_secret = customized_loss(test_output, test_hidden, test_secret, test_cover, beta)\n",
    "    \n",
    "#     diff_S, diff_C = np.abs(np.array(test_output.data[0]) - np.array(test_secret.data[0])), np.abs(np.array(test_hidden.data[0]) - np.array(test_cover.data[0]))\n",
    "    \n",
    "#     print (diff_S, diff_C)\n",
    "    \n",
    "    if idx in [1,2,3,4]:\n",
    "        print ('Total loss: {:.2f} \\nLoss on secret: {:.2f} \\nLoss on cover: {:.2f}'.format(test_loss.data, loss_secret.data, loss_cover.data))\n",
    "\n",
    "        # Creates img tensor\n",
    "        imgs = [test_secret.data, test_output.data, test_cover.data, test_hidden.data]\n",
    "        imgs_tsor = torch.cat(imgs, 0)\n",
    "\n",
    "        # Prints Images\n",
    "        imshow(utils.make_grid(imgs_tsor), idx+1, learning_rate=learning_rate, beta=beta)\n",
    "        \n",
    "    test_losses.append(test_loss.data)\n",
    "        \n",
    "mean_test_loss = np.mean(test_losses)\n",
    "\n",
    "print ('Average loss on test set: {:.2f}'.format(mean_test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
